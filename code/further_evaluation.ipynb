{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "t2iRfT0aihlT"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch\n",
    "import time\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AzxqIXQpimKy"
   },
   "outputs": [],
   "source": [
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp_file.jpg'\n",
    "    ela_filename = 'temp_ela_file.png'\n",
    "    \n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g_1MIWcXin6-"
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path, image_size):\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    return convert_tensor(convert_to_ela_image(image_path, 85).resize(image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yryuaCG4ipwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # label: 0 for fake, 1 for real\n",
    "\n",
    "image_size = (224, 224) \n",
    "path = 'CV-Test/Au'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirname, filename)\n",
    "        X.append(prepare_image(full_path, image_size))\n",
    "        Y.append(1)  \n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZU6MgZcIivqs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224) \n",
    "path = 'CV-Test/Tp'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirname, filename)\n",
    "        X.append(prepare_image(full_path, image_size))\n",
    "        Y.append(0)\n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lVGFMO6Diz2e"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X, Y = shuffle(X, Y, random_state=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LvMRM9gZi2nE"
   },
   "outputs": [],
   "source": [
    "test_iterator = data.DataLoader([[X[i], Y[i]] for i in range(len(Y))],\n",
    "                                 batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "6lYwdLW6jX2t"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    predict_real = 0\n",
    "    predict_fake = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(len(y)):\n",
    "        label = y[index]\n",
    "        predict = top_pred[index]\n",
    "        if int(predict) == 1:\n",
    "            predict_real += 1\n",
    "            if int(label) == 1:\n",
    "                tn += 1\n",
    "            if int(label) == 0:\n",
    "                fn += 1\n",
    "            \n",
    "        if int(predict) == 0:\n",
    "            predict_fake += 1\n",
    "            if int(label) == 0:\n",
    "                tp += 1\n",
    "            if int(label) == 1:\n",
    "                fp += 1\n",
    "        \n",
    "    return predict_real, predict_fake, tp, fp, tn, fn,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "8U2PVoZ1jI1r"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            predict_real, predict_fake, tp, fp, tn, fn,acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return predict_real, predict_fake, tp, fp, tn, fn, epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "J_xJ0i2klv1c"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR4dr7LFi7oD"
   },
   "source": [
    "# VGG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "4aWMNZpXi5dN"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 4096),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5), \n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "6LRiVvCpi_mr"
   },
   "outputs": [],
   "source": [
    "def get_vgg_layers(config, batch_norm):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.LeakyReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.LeakyReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gf3BakoWjC3R"
   },
   "outputs": [],
   "source": [
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M']\n",
    "vgg16_layers = get_vgg_layers(vgg16_config, batch_norm=True)\n",
    "\n",
    "OUTPUT_DIM = 2\n",
    "model = VGG(vgg16_layers, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "YQY9nS7QjEUN"
   },
   "outputs": [],
   "source": [
    "pretrained_model = models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1DMEQJ-xjE4Z"
   },
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.classifier[-1].in_features\n",
    "\n",
    "final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "pretrained_model.classifier[-1] = final_fc\n",
    "\n",
    "pretrained_model.features = pretrained_model.features[:24]\n",
    "pretrained_model.classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "zjV-R5_MjYzd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted real images: 89\n",
      "The number of predicted fake images: 111\n",
      "The number of correctly predicted real images: 85\n",
      "The number of correctly predicted fake images: 96\n",
      "The number of predicted fake images that should be real: 15\n",
      "The number of predicted real images that should be fake: 4\n",
      "precision: 0.8648648648648649\n",
      "recall: 0.96\n",
      "f1 score: 0.9099526066350712\n",
      "test loss: 0.2938739061355591\n",
      "test accuracy: 0.9049999713897705\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('VGG10/VGG10-copymove-best.pt'))\n",
    "model = model.to(device)\n",
    "predict_real, predict_fake, tp, fp, tn, fn, test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('The number of predicted real images: {}'.format(predict_real))\n",
    "print('The number of predicted fake images: {}'.format(predict_fake))\n",
    "print('The number of correctly predicted real images: {}'.format(tn))\n",
    "print('The number of correctly predicted fake images: {}'.format(tp))\n",
    "print('The number of predicted fake images that should be real: {}'.format(fp))\n",
    "print('The number of predicted real images that should be fake: {}'.format(fn))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('f1 score: {}'.format(f1))\n",
    "print('test loss: {}'.format(test_loss))\n",
    "print('test accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNygURYQlRM3"
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_layers(config, batch_norm):\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
    "                'M', 512, 512, 512, 'M']\n",
    "vgg16_layers = get_vgg_layers(vgg16_config, batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = VGG(vgg16_layers, OUTPUT_DIM)\n",
    "pretrained_model = models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.classifier[-1].in_features\n",
    "\n",
    "final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "pretrained_model.classifier[-1] = final_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "WnQxKFyGlhfd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted real images: 91\n",
      "The number of predicted fake images: 109\n",
      "The number of correctly predicted real images: 84\n",
      "The number of correctly predicted fake images: 93\n",
      "The number of predicted fake images that should be real: 16\n",
      "The number of predicted real images that should be fake: 7\n",
      "precision: 0.8532110091743119\n",
      "recall: 0.93\n",
      "f1 score: 0.8899521531100477\n",
      "test loss: 0.2539728581905365\n",
      "test accuracy: 0.8849999904632568\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('VGG16/VGG16-copymove-best.pt'))\n",
    "model = model.to(device)\n",
    "predict_real, predict_fake, tp, fp, tn, fn, test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('The number of predicted real images: {}'.format(predict_real))\n",
    "print('The number of predicted fake images: {}'.format(predict_fake))\n",
    "print('The number of correctly predicted real images: {}'.format(tn))\n",
    "print('The number of correctly predicted fake images: {}'.format(tp))\n",
    "print('The number of predicted fake images that should be real: {}'.format(fp))\n",
    "print('The number of predicted real images that should be fake: {}'.format(fn))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('f1 score: {}'.format(f1))\n",
    "print('test loss: {}'.format(test_loss))\n",
    "print('test accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u8OUMR2lUCV"
   },
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the ResNet architecture\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                               stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "            \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "            \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [2,2,2,2],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet34_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [3,4,6,3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "resnet50_config = ResNetConfig(block = Bottleneck,\n",
    "                               n_blocks = [3, 4, 6, 3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet101_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 4, 23, 3],\n",
    "                                channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet152_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 8, 36, 3],\n",
    "                                channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = ResNet(resnet18_config, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "      nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "      if m.bias is not None:\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "      nn.init.constant_(m.weight.data, 1)\n",
    "      nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/featurize/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd25191babf84bf39d1921acc0d2beb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "pretrained_model = models.resnet18(pretrained = True)\n",
    "\n",
    "IN_FEATURES = pretrained_model.fc.in_features \n",
    "\n",
    "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "pretrained_model.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "s8opWjWFlmUX"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted real images: 91\n",
      "The number of predicted fake images: 109\n",
      "The number of correctly predicted real images: 83\n",
      "The number of correctly predicted fake images: 92\n",
      "The number of predicted fake images that should be real: 17\n",
      "The number of predicted real images that should be fake: 8\n",
      "precision: 0.8440366972477065\n",
      "recall: 0.92\n",
      "f1 score: 0.8803827751196172\n",
      "test loss: 0.2973495125770569\n",
      "test accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('ResNet/resnet-copymove-best.pt'))\n",
    "model = model.to(device)\n",
    "predict_real, predict_fake, tp, fp, tn, fn, test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('The number of predicted real images: {}'.format(predict_real))\n",
    "print('The number of predicted fake images: {}'.format(predict_fake))\n",
    "print('The number of correctly predicted real images: {}'.format(tn))\n",
    "print('The number of correctly predicted fake images: {}'.format(tp))\n",
    "print('The number of predicted fake images that should be real: {}'.format(fp))\n",
    "print('The number of predicted real images that should be fake: {}'.format(fn))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('f1 score: {}'.format(f1))\n",
    "print('test loss: {}'.format(test_loss))\n",
    "print('test accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # label: 0 for fake, 1 for real\n",
    "\n",
    "image_size = (32, 32) \n",
    "path = 'CV-Test/Au'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirname, filename)\n",
    "        X.append(prepare_image(full_path, image_size))\n",
    "        Y.append(1)  \n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "path = 'CV-Test/Tp'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirname, filename)\n",
    "        X.append(prepare_image(full_path, image_size))\n",
    "        Y.append(0)\n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X, Y = shuffle(X, Y, random_state=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = data.DataLoader([[X[i], Y[i]] for i in range(len(Y))],\n",
    "                                 batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "        # Convolution layer(feature extracction)\n",
    "        self.features = nn.Sequential(\n",
    "            # layer 1 \n",
    "            nn.Conv2d(3, 64, 3, 2, 1), \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(64), # batch normalization \n",
    "            nn.LeakyReLU(inplace=True), # leaky relu as our activation function\n",
    "            # layer 2\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # layer 3\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # layer 4\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # layer 5\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        # Fully connected layer(classification)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.LeakyReLU(inplace=True), \n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model = AlexNet(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted real images: 104\n",
      "The number of predicted fake images: 96\n",
      "The number of correctly predicted real images: 86\n",
      "The number of correctly predicted fake images: 82\n",
      "The number of predicted fake images that should be real: 14\n",
      "The number of predicted real images that should be fake: 18\n",
      "precision: 0.8541666666666666\n",
      "recall: 0.82\n",
      "f1 score: 0.836734693877551\n",
      "test loss: 0.34927788376808167\n",
      "test accuracy: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('AlexNet/alex-copymove-model-best.pt'))\n",
    "model = model.to(device)\n",
    "predict_real, predict_fake, tp, fp, tn, fn, test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('The number of predicted real images: {}'.format(predict_real))\n",
    "print('The number of predicted fake images: {}'.format(predict_fake))\n",
    "print('The number of correctly predicted real images: {}'.format(tn))\n",
    "print('The number of correctly predicted fake images: {}'.format(tp))\n",
    "print('The number of predicted fake images that should be real: {}'.format(fp))\n",
    "print('The number of predicted real images that should be fake: {}'.format(fn))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('f1 score: {}'.format(f1))\n",
    "print('test loss: {}'.format(test_loss))\n",
    "print('test accuracy: {}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
